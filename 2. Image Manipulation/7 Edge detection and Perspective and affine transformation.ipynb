{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:\\[FreeTutorials.Us] master-computer-vision-with-opencv-in-python\\master-computer-vision-codes\\2. Image Manipulation\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('G:\\[FreeTutorials.Us] master-computer-vision-with-opencv-in-python\\material\\Master OpenCV\\images\\input.jpg',0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'image4.png'>\n",
    "<img src = 'image3.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "height,width = image.shape\n",
    "\n",
    "#extracting sobel edges\n",
    "sobel_x = cv2.Sobel(image,cv2.CV_64F,0,1,ksize = 5)\n",
    "sobel_y = cv2.Sobel(image,cv2.CV_64F,1,0,ksize = 5)\n",
    "\n",
    "cv2.imshow('Original',image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.imshow('sobel_x',sobel_x)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.imshow('sobel_y',sobel_y)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "sobel = cv2.bitwise_or(sobel_x,sobel_y)\n",
    "cv2.imshow('sobel',sobel)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "laplacian = cv2.Laplacian(image,cv2.CV_64F)\n",
    "cv2.imshow('Laplacian',laplacian)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Canny Edge detection\n",
    "# We need to provide two threshold values, thresh1 and thresh2. Any gradient value larger than thresh2 is classified\n",
    "# as an edge. Any value below thresh1 is not considered as an edge. Values in between can be classified as either edge\n",
    "# not an edge depending on how their 'intensities' are connected.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "canny = cv2.Canny(image,5,15)\n",
    "cv2.imshow('Canny',canny)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:\\[FreeTutorials.Us] master-computer-vision-with-opencv-in-python\\master-computer-vision-codes\\2. Image Manipulation\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('G:\\[FreeTutorials.Us] master-computer-vision-with-opencv-in-python\\material\\Master OpenCV\\images\\scan.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('Original',image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# four corners of the original image\n",
    "points_A = np.float32([[320,15],[700,215],[85,610],[530,780]])\n",
    "# four coordinates of the output image based A4 size\n",
    "points_B = np.float32([[0,0],[420,0],[0,594],[420,594]])\n",
    "\n",
    "# calculate the perspective transformation matrix\n",
    "M = cv2.getPerspectiveTransform(points_A,points_B)\n",
    "warped = cv2.warpPerspective(image,M,(420,594))\n",
    "\n",
    "cv2.imshow('Warped Image',warped)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Affine Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('G:\\[FreeTutorials.Us] master-computer-vision-with-opencv-in-python\\material\\Master OpenCV\\images\\ex2.jpg')\n",
    "rows,cols,chs = image.shape\n",
    "\n",
    "cv2.imshow('Original',image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# coordinates of the original image. In affine transformation we only need 3 points\n",
    "\n",
    "\n",
    "points_A = np.float32([[320,15],[700,215],[85,610]])\n",
    "points_B = np.float32([[0,0],[420,0],[0,594]])\n",
    "\n",
    "M = cv2.getAffineTransform(points_A,points_B)\n",
    "warped = cv2.warpAffine(image,M,(rows,cols))\n",
    "\n",
    "cv2.imshow('Warped image',warped)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
